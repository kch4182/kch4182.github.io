{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "머신러닝_과제4",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgyJ5IMyLA6G"
      },
      "source": [
        "# 학번 : 2017250050\n",
        "# 이름 : 조현석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUWxpe9RLAwn"
      },
      "source": [
        "# 과제 1\n",
        "\n",
        "조기 종료를 사용한 배치 경사 하강법으로 로지스틱 회귀를 구현하라. 단, 사이킷런을 전혀 사용하지 않아야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzYhmfKFEme0"
      },
      "source": [
        "## 1. 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Tqzjs1FOSy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt # from matplot import pyplot as plt 똑같은 의미\n",
        "from sklearn import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAqvrBRl9JcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54732ffd-e05f-4d09-931f-110488f10f6b"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "\n",
        "# 꽃잎의 너비 2인 붓꽃의 품종은 버지니카이다.\n",
        "X = iris[\"data\"][:, (2, 3)]  # 꽃잎 길이, 너비\n",
        "\n",
        "# iris[\"target\"]에서 꽃잎 너비가 2일 때만 True값 발생\n",
        "y = (iris[\"target\"] == 2).astype(np.int) \n",
        "\n",
        "# y를 int형으로 변환\n",
        "# 버지니카는 1로 나머지는 0으로 변환\n",
        "# y = y.astype(np.int)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L94-zioHEsgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a02d663-e418-4170-b526-7e222db85d8d"
      },
      "source": [
        "# 샘플에 편향 추가\n",
        "\n",
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]\n",
        "# 결과를 일정하게 유지하기 위해 랜덤 시드 지정\n",
        "np.random.seed(2042)\n",
        "\n",
        "print(X_with_bias[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.  1.4 0.2]\n",
            " [1.  1.4 0.2]\n",
            " [1.  1.3 0.2]\n",
            " [1.  1.5 0.2]\n",
            " [1.  1.4 0.2]\n",
            " [1.  1.7 0.4]\n",
            " [1.  1.4 0.3]\n",
            " [1.  1.5 0.2]\n",
            " [1.  1.4 0.2]\n",
            " [1.  1.5 0.1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXYjDGX1Iby1"
      },
      "source": [
        "## 2. 데이터셋 분할\n",
        "\n",
        "데이터셋을 훈련, 검증, 테스트 용도로 6대 2대 2의 비율로 무작위로 분할한다.\n",
        "\n",
        "* 훈련 세트: 60%\n",
        "* 검증 세트: 20%\n",
        "* 테스트 세트: 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B7f0y1hEseA"
      },
      "source": [
        "test_ratio = 0.2                                         # 테스트 세트 비율 = 20%\n",
        "validation_ratio = 0.2                                   # 검증 세트 비율 = 20%\n",
        "total_size = len(X_with_bias)                            # 전체 데이터셋 크기\n",
        "\n",
        "test_size = int(total_size * test_ratio)                 # 테스트 세트 크기: 전체의 20%\n",
        "validation_size = int(total_size * validation_ratio)     # 검증 세트 크기: 전체의 20%\n",
        "train_size = total_size - test_size - validation_size    # 훈련 세트 크기: 전체의 60%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXpKZtagEsZk"
      },
      "source": [
        "rnd_indices = np.random.permutation(total_size) # 인덱스를 무작위로 섞는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApUrjdWBEsXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5a0991-1d44-421e-bf6b-47d3e357432d"
      },
      "source": [
        "# 6:2:2로 훈련, 검증, 테스트 세트로 분할\n",
        "\n",
        "# train dataset\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "\n",
        "# validation dataset\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "\n",
        "# test dataset\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]\n",
        "\n",
        "print(\"feature Matrix: \", X_train.shape, X_valid.shape, X_test.shape)\n",
        "print(\"target vector: \", y_train.shape, y_valid.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature Matrix:  (90, 3) (30, 3) (30, 3)\n",
            "target vector:  (90,) (30,) (30,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv8BS6LNyoP3",
        "outputId": "9fe04278-3d6c-484e-ea77-972b96fca2e8"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
            " 0 0 0 1 1 1 1 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0\n",
            " 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv3kS6lSJHi2"
      },
      "source": [
        "## 3. 타깃 변환\n",
        "꽃 종류 0, 1, 2 -> 2나 1에서 숫자크기에 대해 우선순위, 영향을 줄 수 있기 때문에 one hot을 사용하여 범주형 데이터를 바꿔준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPtsW0taEsSH"
      },
      "source": [
        "def to_one_hot(y):\n",
        "    n_classes = y.max() + 1                 # 클래스 수\n",
        "    m = len(y)                              # 샘플 수\n",
        "    Y_one_hot = np.zeros((m, n_classes))    # (샘플 수, 클래스 수) 0-벡터 생성\n",
        "    Y_one_hot[np.arange(m), y] = 1          # 샘플 별로 해당 클래스의 값만 1로 변경. (넘파이 인덱싱 활용)\n",
        "    return Y_one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i1WGk-Ohm_c"
      },
      "source": [
        "Y_train_one_hot = to_one_hot(y_train)\n",
        "Y_valid_one_hot = to_one_hot(y_valid)\n",
        "Y_test_one_hot = to_one_hot(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiGYYmBXhszy"
      },
      "source": [
        "## 4. 로지스틱 회귀 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3VnS6Y0plVT"
      },
      "source": [
        "### 4-1. 시그모이드 함수 정의\n",
        "\n",
        "시그모이드 함수를 정의하여 경사하강법에서 사용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8W_GtHxpbWu"
      },
      "source": [
        "def logistic(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-J4PU1KsQSl"
      },
      "source": [
        "### 4-2. 경사하강법\n",
        "\n",
        "경사하강법을 사용하여 세타 값을 구할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1q-T1E6pbUe"
      },
      "source": [
        "n_inputs = X_train.shape[1]           # 특성 수(n) + 1, 붓꽃의 경우: 특성 2개 + 1\n",
        "n_outputs = len(np.unique(y_train))   # 중복을 제거한 클래스 수(K), 붓꽃의 경우: 3개"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6YbWNlTpbR_"
      },
      "source": [
        "Theta = np.random.randn(n_inputs, 1) # n_inputs -> 특성, n_outputs -> 클래스"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIbr6GzQpbPe",
        "outputId": "130652e5-3320-4a8a-c90f-9af93e8132b0"
      },
      "source": [
        "#  배치 경사하강법 구현\n",
        "eta = 0.1 # 학습률\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "for iteration in range(n_iterations):     # 5001번 반복 훈련\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = logistic(logits)    \n",
        "    \n",
        "    if iteration % 500 == 0:              # 500 에포크마다 손실(비용) 계산해서 출력\n",
        "        loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon) + (1 - Y_train_one_hot ) * np.log(1 - Y_proba + epsilon), axis=1))\n",
        "        print(iteration, loss)       \n",
        "    \n",
        "    # Y_proba = np.where(Y_proba>=0.5,1,0)      # 시그모이드 함수를 사용하여 0.5보다 크면 1, 작으면 0으로 data 값 변경\n",
        "    error = Y_proba - Y_train_one_hot      #  Y_proba -> 0과1, error -> 0 or -1 \n",
        "    gradients = 1/m * X_train.T.dot(error) # -> 세타값 수정,  T -> 전치행렬\n",
        "    \n",
        "    \n",
        "    Theta = Theta - eta * gradients       # 파라미터 업데이트"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.7027587596570046\n",
            "500 0.5989852865925711\n",
            "1000 0.4849055842061277\n",
            "1500 0.4288266121426535\n",
            "2000 0.3925608628462095\n",
            "2500 0.3661475166018786\n",
            "3000 0.3456019193132381\n",
            "3500 0.32894148132145823\n",
            "4000 0.3150377275718563\n",
            "4500 0.30318699641784314\n",
            "5000 0.29292076850443666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHpcHURVgW30"
      },
      "source": [
        "경사하강법을 사용하여 구한 Theta값은 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMwTMhk_pbCh",
        "outputId": "711ef66c-6e3b-41ed-ac5e-8b9096b687ce"
      },
      "source": [
        "Theta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10.5759757 , -10.56492618],\n",
              "       [ -0.53337662,   0.53611169],\n",
              "       [ -4.8419295 ,   4.82694082]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkUdXC3igaPh"
      },
      "source": [
        "Theta값을 활용하여 Y_proba를 구한 뒤 y_predict를 사용하여 y_valid와 비교하여 정확도를 구할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrl0yfyesn_a",
        "outputId": "015bafb8-c95c-49e3-c8f1-f2797cc4465b"
      },
      "source": [
        "logits = X_valid.dot(Theta)              \n",
        "Y_proba = logistic(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)          # 가장 높은 확률을 갖는 클래스 선택\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)  # 정확도 계산\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm-Z1WeytISg"
      },
      "source": [
        "## 5. 규제가 추가된 경사하강법 활용\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dw5efxCtAXV",
        "outputId": "b26ac899-38b9-4544-957e-124c6cfd9592"
      },
      "source": [
        "eta = 0.08\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1        # 규제 하이퍼파라미터\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = logistic(logits)\n",
        "    \n",
        "    if iteration % 500 == 0:\n",
        "        xentropy_loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon) + (1 - Y_train_one_hot ) * np.log(1 - Y_proba + epsilon), axis=1))\n",
        "        l2_loss = 1/2 * np.sum(np.square(Theta[1:]))  # 편향은 규제에서 제외\n",
        "        loss = xentropy_loss + alpha * l2_loss        # l2 규제가 추가된 손실\n",
        "        print(iteration, loss)\n",
        "    \n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    l2_loss_gradients = np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]   # l2 규제 그레이디언트\n",
        "    gradients = 1/m * X_train.T.dot(error) + l2_loss_gradients\n",
        "    \n",
        "    Theta = Theta - eta * gradients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 2.4721259115384857\n",
            "500 0.7522525430412024\n",
            "1000 0.6948762090371331\n",
            "1500 0.6758876636466287\n",
            "2000 0.6680169015595655\n",
            "2500 0.6644016260086401\n",
            "3000 0.6626452212738065\n",
            "3500 0.6617625143327626\n",
            "4000 0.6613091401483169\n",
            "4500 0.6610728661353034\n",
            "5000 0.6609484954749916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxvxBUqxMNTy",
        "outputId": "8211d98a-2e56-4706-c6c9-2e6fb0565af9"
      },
      "source": [
        "len(Y_proba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0t5rED3tjhr",
        "outputId": "63761c49-79d8-4781-becb-5c7ffead13e3"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = logistic(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ySbEjSRtqWu"
      },
      "source": [
        "## 6. 조기 종료 추가\n",
        "\n",
        "모델의 훈련 세트에 대한 과대 적합 방지를 위해 훈련을 적절한 시기에 중단"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPf4SYGAtjcT",
        "outputId": "47d700e8-4e9a-4a24-d3a4-5c5e02e50ee3"
      },
      "source": [
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1            # 규제 하이퍼파라미터\n",
        "best_loss = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = logistic(logits)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits = X_valid.dot(Theta)\n",
        "    Y_proba = logistic(logits)\n",
        "    xentropy_loss = -1/m*(np.sum(Y_valid_one_hot * np.log(Y_proba + epsilon) + (1 - Y_valid_one_hot ) * np.log(1 - Y_proba + epsilon)))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = xentropy_loss + alpha * l2_loss\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.8974463846026375\n",
            "500 0.29227979551382216\n",
            "621 0.2912609834871013\n",
            "622 0.29126103697852784 조기 종료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR13eo1QtjaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3edc6f0-46da-4ab1-9e01-6105661c28f9"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = logistic(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWNAuh-YWDEz"
      },
      "source": [
        "## 7. 전체 데이터셋 대한 예측 결과 그래프\n",
        "\n",
        "그래프에서 노란색과, 초록색을 구분하여 노란색은 Not virginica, 초록색은 virginica이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b20PhRFtjGZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "5b3baa6e-6f88-4466-c7a6-bae19308c213"
      },
      "source": [
        "# (0, 8) x (0, 3.5) 크기의 직사각형 안의 모든 점을 대상으로 예측한 후에\n",
        "# 예측 결과를 이용하여 색상으로 구분하고 등고선도 그리기 위한 준비작업\n",
        "# 가로는 500개의 구간으로, 세로는 200개의 구간으로 쪼개짐.\n",
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(0, 8, 500).reshape(-1, 1),\n",
        "        np.linspace(0, 3.5, 200).reshape(-1, 1),\n",
        "    )\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "X_new_with_bias = np.c_[np.ones([len(X_new), 1]), X_new]\n",
        "\n",
        "# 직사각형 점 대상 예측하기\n",
        "logits = X_new_with_bias.dot(Theta)\n",
        "Y_proba = logistic(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "# 등고선용 정보\n",
        "zz1 = Y_proba[:, 1].reshape(x0.shape)                            # 버시컬러 기준 예측 확률\n",
        "zz = y_predict.reshape(x0.shape)                                 # 예측값\n",
        "\n",
        "# 붓꽃 샘플 그리기\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris virginica\")  # 파랑 사각형 => 버지니카ㅣ \n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Not virginica\")      # 노랑 원 => 버시컬러,세토사\n",
        "\n",
        "# 등고선 그리기\n",
        "from matplotlib.colors import ListedColormap\n",
        "custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "\n",
        "plt.contourf(x0, x1, zz, cmap=custom_cmap)                       # 노랑, 청보라, 녹색 바탕색\n",
        "contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)              # 버시컬러 기준 예측 확률 등고선\n",
        "plt.clabel(contour, inline=1, fontsize=12)\n",
        "\n",
        "# 기타 도표 정보\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.ylabel(\"Petal width\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=14)\n",
        "plt.axis([0, 7, 0, 3.5])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5VHwHbrWAUO"
      },
      "source": [
        "## 8. 데스트 세트 평가\n",
        "\n",
        "구한 Theta 값을 사용하여 Y_proba를 구한 후 y_predict를 구할 수 있다.\n",
        "구한  y_predict를 사용해 y_test랑 비교 후 정확도를 구할 수 있다.\n",
        "해당 Theta를 사용하여 얻은 정확도는 0.93이 나온 것을 확인할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA4iFBVWgmM9"
      },
      "source": [
        "Y_proba는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkdyqfByKs7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fb652b-5a6d-4a43-affe-9fa9453a1611"
      },
      "source": [
        "print(Y_proba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.98028102 0.021777  ]\n",
            " [0.9800897  0.02198107]\n",
            " [0.97989655 0.02218701]\n",
            " ...\n",
            " [0.05235776 0.94459158]\n",
            " [0.05187114 0.94508856]\n",
            " [0.05138879 0.94558134]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQy7U9Y3Vz7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5594959-33d0-4eb9-a887-6e3db07e3dbf"
      },
      "source": [
        "logits = X_test.dot(Theta)\n",
        "Y_proba = logistic(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_test)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yco41bXUK9lW"
      },
      "source": [
        "# 과제 2\n",
        "\n",
        "과제 1에서 구현된 로지스틱 회귀 알고리즘에 일대다(OvR) 방식을 적용하여 붓꽃에 대한 다중 클래스 분류 알고리즘을 구현하라. 단, 사이킷런을 전혀 사용하지 않아야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brjsASHiHK6G"
      },
      "source": [
        "## 1. 데이터 준비\n",
        "\n",
        "과제2에서 필요한 모듈을 import한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZW7cbW6CT9Q"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt # from matplot import pyplot as plt 똑같은 의미\n",
        "from sklearn import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZo-RT207tCY"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris[\"data\"][:, (2, 3)]  # 꽃잎 길이, 꽃잎 넓이\n",
        "y = iris[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYf7u8oA7s_-"
      },
      "source": [
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHnVrCJo7s9r"
      },
      "source": [
        "np.random.seed(2042)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI8wcS_fHP92"
      },
      "source": [
        "## 2. 데이터셋 분할\n",
        "\n",
        "데이터셋을 훈련, 검증, 테스트 용도로 6대 2대 2의 비율로 무작위로 분할한다.\n",
        "\n",
        "* 훈련 세트: 60%\n",
        "* 검증 세트: 20%\n",
        "* 테스트 세트: 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL7CE_i-7s1z"
      },
      "source": [
        "test_ratio = 0.2                                         # 테스트 세트 비율 = 20%\n",
        "validation_ratio = 0.2                                  # 검증 세트 비율 = 20%\n",
        "total_size = len(X_with_bias)                            # 전체 데이터셋 크기\n",
        "\n",
        "test_size = int(total_size * test_ratio)                 # 테스트 세트 크기: 전체의 20%\n",
        "validation_size = int(total_size * validation_ratio)     # 검증 세트 크기: 전체의 20%\n",
        "train_size = total_size - test_size - validation_size    # 훈련 세트 크기: 전체의 60%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZObu6YTP7szg"
      },
      "source": [
        "rnd_indices = np.random.permutation(total_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIi2Lc_o7sw0"
      },
      "source": [
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YguHH53-Mc2g",
        "outputId": "9aa1084b-9811-4eb0-a4e7-e00132d98307"
      },
      "source": [
        "print(y_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 2 0 0 1 2 2 0 0 0 1 1 2 2 1 1 2 1 2 1 0 1 2 2 1 0 0 1 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9mlQFptHZuz"
      },
      "source": [
        "## 3. 타깃 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drXIyNpVCpj4",
        "outputId": "72ce586f-4b57-41c2-b25b-872b1b797844"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QME6e5vu0MId"
      },
      "source": [
        "one_hot을 사용하여 타깃을 변환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QC6CJ1ZHeCi"
      },
      "source": [
        "def to_one_hot(y):\n",
        "    n_classes = y.max() + 1                 # 클래스 수\n",
        "    m = len(y)                              # 샘플 수\n",
        "    Y_one_hot = np.zeros((m, n_classes))    # (샘플 수, 클래스 수) 0-벡터 생성\n",
        "    Y_one_hot[np.arange(m), y] = 1          # 샘플 별로 해당 클래스의 값만 1로 변경. (넘파이 인덱싱 활용)\n",
        "    return Y_one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJYeIN3rHgoW"
      },
      "source": [
        "Y_train_one_hot = to_one_hot(y_train)\n",
        "Y_valid_one_hot = to_one_hot(y_valid)\n",
        "Y_test_one_hot = to_one_hot(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdQLRX-vb-Pz"
      },
      "source": [
        "to_one_hot을 사용하여 Y_train_one_hot을 다음과 같은 형태로 작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkdyJMo90R03",
        "outputId": "8de18b05-d188-4490-b1bd-ac79c4cbedd9"
      },
      "source": [
        "print(Y_train_one_hot[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ndqpOtVfDXv"
      },
      "source": [
        "## 4. 데이터 구분\n",
        "\n",
        "Y_train_one_hot을 꽃 3가지로 분류해서 사용\n",
        "\n",
        "* Y_A : Iris-Setosa(세토사)\n",
        "* Y_B : Iris-Versicolor(버시컬러)\n",
        "* Y_C : Iris-Virginica(버지니카) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMH-TDegfGQH"
      },
      "source": [
        "# np.array 선언\n",
        "Y_A_train = np.array([])\n",
        "Y_B_train = np.array([])\n",
        "Y_C_train = np.array([])\n",
        "\n",
        "Y_A_valid = np.array([])\n",
        "Y_B_valid = np.array([])\n",
        "Y_C_valid = np.array([])\n",
        "\n",
        "Y_A_test = np.array([])\n",
        "Y_B_test = np.array([])\n",
        "Y_C_test = np.array([])\n",
        "\n",
        "# for문을 사용해서 Y_train_one_hot에서 각각의 열을 변수에 따로 넣는다.\n",
        "# Y_A_train에 첫번째 행만 넣을 것이다.\n",
        "for i in Y_train_one_hot :\n",
        "  j = 0\n",
        "  Y_A_train = np.append(Y_A_train, np.array(i[j]))\n",
        "\n",
        "# Y_B_trian에 두번째 행만 넣을 것이다.\n",
        "for i in Y_train_one_hot :\n",
        "  j = 1\n",
        "  Y_B_train = np.append(Y_B_train, np.array(i[j]))\n",
        "\n",
        "# Y_C_trian에 세번째 행만 넣을 것이다.\n",
        "for i in Y_train_one_hot :\n",
        "  j = 2\n",
        "  Y_C_train = np.append(Y_C_train, np.array(i[j]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUx57i1HDeXN"
      },
      "source": [
        "for문을 사용해서 Y_valid_one_hot에서 각각의 열을 변수에 따로 넣는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc10EcdwDhGU"
      },
      "source": [
        "# Y_A_valid에 첫번째 행만 넣을 것이다.\n",
        "for i in Y_valid_one_hot :\n",
        "  j = 0\n",
        "  Y_A_valid = np.append(Y_A_valid, np.array(i[j]))\n",
        "\n",
        "# Y_B_valid에 두번째 행만 넣을 것이다.\n",
        "for i in Y_valid_one_hot :\n",
        "  j = 1\n",
        "  Y_B_valid = np.append(Y_B_valid, np.array(i[j]))\n",
        "\n",
        "# Y_C_valid에 세번째 행만 넣을 것이다.\n",
        "for i in  Y_valid_one_hot :\n",
        "  j = 2\n",
        "  Y_C_valid = np.append(Y_C_valid, np.array(i[j]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR7wVXlMD9_3"
      },
      "source": [
        "for문을 사용해서 Y_test_one_hot에서 각각의 열을 변수에 따로 넣는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eNAcjtwEBnS"
      },
      "source": [
        "# Y_A_testn에 첫번째 행만 넣을 것이다.\n",
        "for i in Y_test_one_hot :\n",
        "  j = 0\n",
        "  Y_A_test = np.append(Y_A_test, np.array(i[j]))\n",
        "\n",
        "# Y_B_test에 두번째 행만 넣을 것이다.\n",
        "for i in Y_test_one_hot :\n",
        "  j = 1\n",
        "  Y_B_test = np.append(Y_B_test, np.array(i[j]))\n",
        "\n",
        "# Y_C_test에 세번째 행만 넣을 것이다.\n",
        "for i in  Y_test_one_hot :\n",
        "  j = 2\n",
        "  Y_C_test = np.append(Y_C_test, np.array(i[j]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma27vr1-eGIb"
      },
      "source": [
        "각각의 데이터를 사용하기 위하여 reshape를 사용하여 배열의 형태를 맞춰준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yHWSqq-E32k"
      },
      "source": [
        "Y_A_train= Y_A_train.reshape(90,1)\n",
        "Y_B_train= Y_B_train.reshape(90,1)\n",
        "Y_C_train= Y_C_train.reshape(90,1)\n",
        "\n",
        "Y_A_valid= Y_A_valid.reshape(30,1)\n",
        "Y_B_valid= Y_B_valid.reshape(30,1)\n",
        "Y_C_valid= Y_C_valid.reshape(30,1)\n",
        "\n",
        "y_valid = np.reshape(y_valid,(30,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMO25RhmHdAF"
      },
      "source": [
        "## 5. 일대다 방식 로지스틱 회귀 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_YJsNPoIjiX"
      },
      "source": [
        "### 5-1. 시그모이드 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx0eLZzTH-m-"
      },
      "source": [
        "def logistic(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrR9-uGKImfS"
      },
      "source": [
        "### 5-2. 경사하강법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PdbEmFoInHn"
      },
      "source": [
        "n_inputs = X_train.shape[1]           # 특성 수(n) + 1, 붓꽃의 경우: 특성 2개 + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hyy3rh2emC9"
      },
      "source": [
        "각각 꽃들의 Theta값을 따로 구한다.\n",
        "\n",
        "* Theta_A : Iris-Setosa(세토사)\n",
        "* Theta_B : Iris-Versicolor(버시컬러)\n",
        "* Theta_C : Iris-Virginica(버지니카) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ5RqEe-Ioeu"
      },
      "source": [
        "Theta_A = np.random.randn(n_inputs, 1) # n_inputs -> 특성, n_outputs -> 클래스\n",
        "Theta_B = np.random.randn(n_inputs, 1)\n",
        "Theta_C = np.random.randn(n_inputs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z67dYCZFAPTw"
      },
      "source": [
        "#### 5-2-1. Y_A 경사하강법 이용하여 세타값 구하기\n",
        "\n",
        "Y_train_one_hot 대신 Y_A값 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkljT6U__W0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3748f3f-14ab-4b26-f7e5-9e6c44a4f7b5"
      },
      "source": [
        "#  배치 경사하강법 구현\n",
        "eta = 0.01 # 학습률\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "for iteration in range(n_iterations):     # 5001번 반복 훈련\n",
        "    logits = X_train.dot(Theta_A)\n",
        "    Y_proba = logistic(logits)            # 양성확률\n",
        "    \n",
        "    if iteration % 500 == 0:              # 500 에포크마다 손실(비용) 계산해서 출력\n",
        "        loss = -1/m*(np.sum(Y_A_train * np.log(Y_proba + epsilon) + (1 - Y_A_train ) * np.log(1 - Y_proba + epsilon)))\n",
        "        print(iteration, loss)       \n",
        "        \n",
        "    # Y_proba = np.where(Y_proba>=0.5,1,0)      # 시그모이드 함수를 사용하여 0.5보다 크면 1, 작으면 0으로 data 값 변경\n",
        "    error = Y_proba - Y_A_train      #  Y_proba -> 0과1, error -> 0 or -1 \n",
        "    gradients = 1/m * X_train.T.dot(error) # -> 세타값 수정,  T -> 전치행렬\n",
        "    \n",
        "    \n",
        "    Theta_A = Theta_A - eta * gradients      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.4375778183535419\n",
            "500 0.31431995535530344\n",
            "1000 0.24739460329867496\n",
            "1500 0.2015867449720451\n",
            "2000 0.16903839269298135\n",
            "2500 0.14505018722266635\n",
            "3000 0.12678834326159452\n",
            "3500 0.11249465278438289\n",
            "4000 0.10104061337268973\n",
            "4500 0.09167722680238735\n",
            "5000 0.08389173872084243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIFQ9g3XAaJH"
      },
      "source": [
        "#### 5-2-2. Y_B 경사하강법 이용하여 세타값 구하기\n",
        "\n",
        "Y_train_one_hot 대신 Y_B값 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ1tUTSjAfKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a37021b-e018-4b90-d7da-b1020f2cb7ce"
      },
      "source": [
        "#  배치 경사하강법 구현\n",
        "eta = 0.01 # 학습률\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "for iteration in range(n_iterations):     # 5001번 반복 훈련\n",
        "    logits = X_train.dot(Theta_B)\n",
        "    Y_proba = logistic(logits)            # 양성확률\n",
        "    \n",
        "    if iteration % 500 == 0:              # 500 에포크마다 손실(비용) 계산해서 출력\n",
        "        loss = -1/m*(np.sum(Y_B_train * np.log(Y_proba + epsilon) + (1 - Y_B_train ) * np.log(1 - Y_proba + epsilon)))\n",
        "        print(iteration, loss)       \n",
        "        \n",
        "    # Y_proba = np.where(Y_proba>=0.5,1,0)      # 시그모이드 함수를 사용하여 0.5보다 크면 1, 작으면 0으로 data 값 변경\n",
        "    error = Y_proba - Y_B_train      #  Y_proba -> 0과1, error -> 0 or -1 \n",
        "    gradients = 1/m * X_train.T.dot(error) # -> 세타값 수정,  T -> 전치행렬\n",
        "    \n",
        "    \n",
        "    Theta_B = Theta_B - eta * gradients    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.2606929830898994\n",
            "500 0.6772281840254408\n",
            "1000 0.6495112807463842\n",
            "1500 0.6321202145095705\n",
            "2000 0.6208586756639016\n",
            "2500 0.61327529751536\n",
            "3000 0.6079464920366938\n",
            "3500 0.604036172333173\n",
            "4000 0.6010441944343213\n",
            "4500 0.5986650864781039\n",
            "5000 0.5967082592695107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPfuTnEJAavj"
      },
      "source": [
        "#### 5-2-3. Y_C 경사하강법 이용하여 세타값 구하기\n",
        "\n",
        "Y_train_one_hot 대신 Y_C값 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0goCcWLAfvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef381da-5663-4762-80c2-c8754aaabf26"
      },
      "source": [
        "#  배치 경사하강법 구현\n",
        "eta = 0.01 # 학습률\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "for iteration in range(n_iterations):     # 5001번 반복 훈련\n",
        "    logits = X_train.dot(Theta_C)\n",
        "    Y_proba = logistic(logits)            # 양성확률\n",
        "    \n",
        "    if iteration % 500 == 0:              # 500 에포크마다 손실(비용) 계산해서 출력\n",
        "        loss = -1/m*(np.sum(Y_C_train * np.log(Y_proba + epsilon) + (1 - Y_C_train ) * np.log(1 - Y_proba + epsilon)))\n",
        "        print(iteration, loss)       \n",
        "        \n",
        "    # Y_proba = np.where(Y_proba>=0.5,1,0)      # 시그모이드 함수를 사용하여 0.5보다 크면 1, 작으면 0으로 data 값 변경\n",
        "    error = Y_proba - Y_C_train      #  Y_proba -> 0과1, error -> 0 or -1 \n",
        "    gradients = 1/m * X_train.T.dot(error) # -> 세타값 수정,  T -> 전치행렬\n",
        "    \n",
        "    \n",
        "    Theta_C = Theta_C - eta * gradients    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.24300345889263\n",
            "500 0.7225341776177694\n",
            "1000 0.5840168541020665\n",
            "1500 0.4994640056646242\n",
            "2000 0.4444430012538986\n",
            "2500 0.4061493368052233\n",
            "3000 0.3779307885022022\n",
            "3500 0.3561651077443095\n",
            "4000 0.3387606059745092\n",
            "4500 0.32443981789478005\n",
            "5000 0.31238297396779313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4XrQphdcI8I"
      },
      "source": [
        "세가지 꽃들을 경사하강법을 사용한 Theta값을 구하여 90행 3열의 형태로 하나로 합침\n",
        "\n",
        "각각의 Theta값을 사용하여 y_predict을 만든다.\n",
        "\n",
        "y_predict을 사용하여 y_valid와 비교하여 정확도를 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDHzj2VjHYTE",
        "outputId": "2fb89c20-b467-407e-f9ca-164d5bb2ca00"
      },
      "source": [
        "logits_A = X_valid.dot(Theta_A)              \n",
        "Y_proba_A = logistic(logits_A)\n",
        "\n",
        "logits_B = X_valid.dot(Theta_B)              \n",
        "Y_proba_B = logistic(logits_B)\n",
        "\n",
        "logits_C = X_valid.dot(Theta_C)              \n",
        "Y_proba_C = logistic(logits_C)\n",
        "\n",
        "Y_proba = np.hstack((Y_proba_A,Y_proba_B,Y_proba_C))      # 각각의 Y_proba를 하나의 Y_proba로 합친다.\n",
        "y_predict = np.argmax(Y_proba, axis=1) # 가장 높은 확률을 갖는 클래스 선택\n",
        "\n",
        "y_predict = np.reshape(y_predict,(30,1))\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid) # 정확도 계산\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZmhvoenQo9S"
      },
      "source": [
        "## 6. 규제가 추가된 경사하강법 활용 훈련\n",
        "\n",
        "규제가 추가된 경사하강법을 활용한 Theta값을 구하여 90행 3열의 형태로 하나로 합침\n",
        "\n",
        "각각의 Theta값을 사용하여 y_predict을 만든다.\n",
        "\n",
        "y_predict을 사용하여 y_valid와 비교하여 정확도를 계산한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccxuOkXIRV7n"
      },
      "source": [
        "### 6-1. Y_A 규제 추가된 경사하강법 활용\n",
        "\n",
        "손실함수를 사용하여 규제 추가된 경사하강법을 활용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s99W6vyHYQt",
        "outputId": "a732c20c-e18e-4575-a66d-baf4688f4be8"
      },
      "source": [
        "eta = 0.08\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1        # 규제 하이퍼파라미터\n",
        "\n",
        "Theta_A = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta_A)\n",
        "    Y_proba = logistic(logits)\n",
        "    \n",
        "    if iteration % 500 == 0:\n",
        "        xentropy_loss = -1/m*(np.sum(Y_A_train * np.log(Y_proba + epsilon) + (1 - Y_A_train ) * np.log(1 - Y_proba + epsilon)))\n",
        "        l2_loss = 1/2 * np.sum(np.square(Theta_A[1:]))  # 편향은 규제에서 제외\n",
        "        loss = xentropy_loss + alpha * l2_loss        # l2 규제가 추가된 손실\n",
        "        print(iteration, loss)\n",
        "    \n",
        "    error = Y_proba -Y_A_train\n",
        "    l2_loss_gradients = np.r_[np.zeros([1, 1]), alpha * Theta_A[1:]]   # l2 규제 그레이디언트\n",
        "    gradients = 1/m * X_train.T.dot(error) + l2_loss_gradients\n",
        "    \n",
        "    Theta_A = Theta_A - eta * gradients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3.1352627662530685\n",
            "500 0.19750727324399006\n",
            "1000 0.18458393190013694\n",
            "1500 0.18281940095844817\n",
            "2000 0.18252746573662926\n",
            "2500 0.18247550285041686\n",
            "3000 0.182465972642171\n",
            "3500 0.18246420250557344\n",
            "4000 0.18246387193649002\n",
            "4500 0.18246381006055457\n",
            "5000 0.1824637984676184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf4N0a6rXjvz"
      },
      "source": [
        "### 6-2. Y_B 규제 추가된 경사하강법 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPMrixSnXq6b",
        "outputId": "ef79a8be-0250-4dcc-d0a5-98d4b58370ba"
      },
      "source": [
        "eta = 0.08\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1        # 규제 하이퍼파라미터\n",
        "\n",
        "Theta_B = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta_B)\n",
        "    Y_proba = logistic(logits)\n",
        "    \n",
        "    if iteration % 500 == 0:\n",
        "        xentropy_loss = -1/m*(np.sum(Y_B_train * np.log(Y_proba + epsilon) + (1 - Y_B_train ) * np.log(1 - Y_proba + epsilon)))\n",
        "        l2_loss = 1/2 * np.sum(np.square(Theta_B[1:]))  # 편향은 규제에서 제외\n",
        "        loss = xentropy_loss + alpha * l2_loss        # l2 규제가 추가된 손실\n",
        "        print(iteration, loss)\n",
        "    \n",
        "    error = Y_proba -Y_B_train\n",
        "    l2_loss_gradients = np.r_[np.zeros([1, 1]), alpha * Theta_B[1:]]   # l2 규제 그레이디언트\n",
        "    gradients = 1/m * X_train.T.dot(error) + l2_loss_gradients\n",
        "    \n",
        "    Theta_B = Theta_B - eta * gradients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1.7143076904453414\n",
            "500 0.6161779468312925\n",
            "1000 0.6070114879266042\n",
            "1500 0.6065546142771823\n",
            "2000 0.6065281499847942\n",
            "2500 0.6065265601288568\n",
            "3000 0.6065264637577777\n",
            "3500 0.6065264579022768\n",
            "4000 0.6065264575460534\n",
            "4500 0.6065264575243177\n",
            "5000 0.6065264575229762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhOffaWcXkhe"
      },
      "source": [
        "### 6-3. Y_C 규제 추가된 경사하강법 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlX7Lmk6HYOh",
        "outputId": "d8355fa1-a007-453d-f59a-d60cdb03e738"
      },
      "source": [
        "eta = 0.08\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1        # 규제 하이퍼파라미터\n",
        "\n",
        "Theta_C = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta_C)\n",
        "    Y_proba = logistic(logits)\n",
        "    \n",
        "    if iteration % 500 == 0:\n",
        "        xentropy_loss = -1/m*(np.sum(Y_C_train * np.log(Y_proba + epsilon) + (1 - Y_C_train ) * np.log(1 - Y_proba + epsilon)))\n",
        "        l2_loss = 1/2 * np.sum(np.square(Theta_C[1:]))  # 편향은 규제에서 제외C\n",
        "        loss = xentropy_loss + alpha * l2_loss        # l2 규제가 추가된 손실\n",
        "        print(iteration, loss)\n",
        "    \n",
        "    error = Y_proba -Y_C_train\n",
        "    l2_loss_gradients = np.r_[np.zeros([1, 1]), alpha * Theta_C[1:]]   # l2 규제 그레이디언트\n",
        "    gradients = 1/m * X_train.T.dot(error) + l2_loss_gradients\n",
        "    \n",
        "    Theta_C = Theta_C - eta * gradients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3.8854347934040043\n",
            "500 0.3916315460644847\n",
            "1000 0.35154136014068504\n",
            "1500 0.3394978854752998\n",
            "2000 0.3346902658661324\n",
            "2500 0.33252340237374123\n",
            "3000 0.33148207794391515\n",
            "3500 0.3309622809353726\n",
            "4000 0.3306964867467214\n",
            "4500 0.33055838537542803\n",
            "5000 0.3304858426427163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfjb3C3qagpF",
        "outputId": "fa3d7b1f-81bd-42a6-ef61-bae079386be1"
      },
      "source": [
        "logits_A = X_valid.dot(Theta_A)              \n",
        "Y_proba_A = logistic(logits_A)\n",
        "\n",
        "logits_B = X_valid.dot(Theta_B)              \n",
        "Y_proba_B = logistic(logits_B)\n",
        "\n",
        "logits_C = X_valid.dot(Theta_C)              \n",
        "Y_proba_C = logistic(logits_C)\n",
        "\n",
        "Y_proba = np.hstack((Y_proba_A,Y_proba_B,Y_proba_C))      # 각각의 Y_proba를 하나의 Y_proba로 합친다.\n",
        "y_predict = np.argmax(Y_proba, axis=1) # 가장 높은 확률을 갖는 클래스 선택\n",
        "\n",
        "y_predict = np.reshape(y_predict,(30,1))\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid) # 정확도 계산\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkkaZ3l8YNJu"
      },
      "source": [
        "## 7. 조기 종료 추가\n",
        "* 모델의 훈련 세트에 대한 과대 적합 방지를 위해 훈련을 적절한 시기에 중단\n",
        "\n",
        "\n",
        "조기 종료가 추가된 경사하강법을 활용한 Theta값을 구하여 90행 3열의 형태로 하나로 합침\n",
        "\n",
        "각각의 Theta값을 사용하여 y_predict을 만든다.\n",
        "\n",
        "y_predict을 사용하여 y_valid와 비교하여 정확도를 계산한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU3uguCDYy9l"
      },
      "source": [
        "### 7-1. Y_A 조기 종료 추가 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM5mE-1WZO2N",
        "outputId": "a7da9ebe-1123-4325-cf47-2c1122f8d315"
      },
      "source": [
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1            # 규제 하이퍼파라미터\n",
        "best_loss = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta_A = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits = X_train.dot(Theta_A)\n",
        "    Y_proba = logistic(logits)\n",
        "    error = Y_proba - Y_A_train\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, 1]), alpha * Theta_A[1:]]\n",
        "    Theta_A = Theta_A - eta * gradients\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits = X_valid.dot(Theta_A)\n",
        "    Y_proba = logistic(logits)\n",
        "    xentropy_loss = -1/m*(np.sum(Y_A_valid * np.log(Y_proba + epsilon) + (1 - Y_A_valid ) * np.log(1 - Y_proba + epsilon)))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta_A[1:]))\n",
        "    loss = xentropy_loss + alpha * l2_loss\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.3995165833930832\n",
            "219 0.10362511575092215\n",
            "220 0.1036252082368875 조기 종료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2tXLHx1Y6By"
      },
      "source": [
        "### 7-2. Y_A 조기 종료 추가 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTi6-2QdaAJX",
        "outputId": "aa951160-2f5e-4bbf-94f9-783e00979def"
      },
      "source": [
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1            # 규제 하이퍼파라미터\n",
        "best_loss = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta_B = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits = X_train.dot(Theta_B)\n",
        "    Y_proba = logistic(logits)\n",
        "    error = Y_proba - Y_B_train\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, 1]), alpha * Theta_B[1:]]\n",
        "    Theta_B = Theta_B - eta * gradients\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits = X_valid.dot(Theta_B)\n",
        "    Y_proba = logistic(logits)\n",
        "    xentropy_loss = -1/m*(np.sum(Y_B_valid * np.log(Y_proba + epsilon) + (1 - Y_B_valid ) * np.log(1 - Y_proba + epsilon)))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta_B[1:]))\n",
        "    loss = xentropy_loss + alpha * l2_loss\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.37326418539764344\n",
            "324 0.21600122064295363\n",
            "325 0.21600130976429946 조기 종료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYDE_bVyY555"
      },
      "source": [
        "### 7-3. Y_C 조기 종료 추가 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U2YK86tHYJP",
        "outputId": "93ec4339-d2db-4b1a-9c59-59d2874a2cfe"
      },
      "source": [
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1            # 규제 하이퍼파라미터\n",
        "best_loss = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta_C = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits = X_train.dot(Theta_C)\n",
        "    Y_proba = logistic(logits)\n",
        "    error = Y_proba - Y_C_train\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, 1]), alpha * Theta_C[1:]]\n",
        "    Theta_C = Theta_C - eta * gradients\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits = X_valid.dot(Theta_C)\n",
        "    Y_proba = logistic(logits)\n",
        "    xentropy_loss = -1/m*(np.sum(Y_C_valid * np.log(Y_proba + epsilon) + (1 - Y_C_valid ) * np.log(1 - Y_proba + epsilon)))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta_C[1:]))\n",
        "    loss = xentropy_loss + alpha * l2_loss\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss) \n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.5103201605141204\n",
            "500 0.14695352666173356\n",
            "678 0.14564268720871207\n",
            "679 0.14564273301583935 조기 종료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toX12EYUHYG9",
        "outputId": "7bcd44d6-5b99-42fc-956f-3c94a75af0e5"
      },
      "source": [
        "logits_A = X_valid.dot(Theta_A)              \n",
        "Y_proba_A = logistic(logits_A)\n",
        "\n",
        "logits_B = X_valid.dot(Theta_B)              \n",
        "Y_proba_B = logistic(logits_B)\n",
        "\n",
        "logits_C = X_valid.dot(Theta_C)              \n",
        "Y_proba_C = logistic(logits_C)\n",
        "\n",
        "Y_proba = np.hstack((Y_proba_A,Y_proba_B,Y_proba_C))      # 각각의 Y_proba를 하나의 Y_proba로 합친다.\n",
        "y_predict = np.argmax(Y_proba, axis=1) # 가장 높은 확률을 갖는 클래스 선택\n",
        "\n",
        "y_predict = np.reshape(y_predict,(30,1))\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid) # 정확도 계산\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sgwv0iHasdz"
      },
      "source": [
        "## 8. 테스트 세트 평가\n",
        "\n",
        "마지막으로 y_predict와 y_test를 비교하여 정확도를 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiGDvjZyawo2",
        "outputId": "1b6fbe4b-1b13-4365-9b93-7fe3aa57b396"
      },
      "source": [
        "logits_A = X_test.dot(Theta_A)              \n",
        "Y_proba_A = logistic(logits_A)\n",
        "\n",
        "logits_B = X_test.dot(Theta_B)              \n",
        "Y_proba_B = logistic(logits_B)\n",
        "\n",
        "logits_C = X_test.dot(Theta_C)              \n",
        "Y_proba_C = logistic(logits_C)\n",
        "\n",
        "Y_proba = np.hstack((Y_proba_A,Y_proba_B,Y_proba_C))      # 각각의 Y_proba를 하나의 Y_proba로 합친다.\n",
        "y_predict = np.argmax(Y_proba, axis=1) # 가장 높은 확률을 갖는 클래스 선택\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_test) # 정확도 계산\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    }
  ]
}